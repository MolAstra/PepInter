name: pepinter_affinity
stage: train
log_dir: ./logs/${stage}
seed: 42

is_resume: false
resume_model_path: null
is_check_data_module: false
exit_after_check: true
is_pretrained: true
pretrained_model_path: logs/train/pepinter_energy/20251108/checkpoints/step=561456-val_loss=0.01.ckpt
# pretrained_model_path: logs/train/pepinter_mlm/version_0/checkpoints/step=741516-val_loss=0.41.ckpt

data_module:
  train_data_path: /home/silong/projects/astra/tmp/pepinter/train_0.csv
  val_data_path: /home/silong/projects/astra/tmp/pepinter/valid_0.csv
  batch_size: 24
  num_workers: 8

lightning_module:
  model_args:
    problem_type: "regression"
    num_labels: 1
  load_from_esmc: false
  learning_rate: 1e-5

trainer:
  _target_: lightning.Trainer
  max_epochs: 50
  log_every_n_steps: 30
  accelerator: "gpu"
  devices: [0]
  strategy: auto
  precision: bf16-mixed
  fast_dev_run: false
  gradient_clip_val: 1.0
  enable_checkpointing: false

  callbacks:
    # - _target_: lightning.pytorch.callbacks.ModelCheckpoint
    #   filename: "{step}-{val_loss:.2f}"
    #   save_top_k: 1
    #   monitor: "val_loss"
    #   mode: "min"
    #   save_last: false
    #   save_weights_only: false
    - _target_: lightning.pytorch.callbacks.LearningRateMonitor
      logging_interval: "step"
    - _target_: lightning.pytorch.callbacks.RichProgressBar

  logger:
    _target_: lightning.pytorch.loggers.CSVLogger
    save_dir: ${log_dir}
    name: ${name}

hydra:
  run:
    dir: ${log_dir}/${name}
